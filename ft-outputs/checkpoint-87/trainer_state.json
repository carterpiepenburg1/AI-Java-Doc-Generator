{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.9942857142857143,
  "eval_steps": 500,
  "global_step": 87,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011428571428571429,
      "grad_norm": 0.487857460975647,
      "learning_rate": 0.0,
      "loss": 2.0506,
      "step": 1
    },
    {
      "epoch": 0.022857142857142857,
      "grad_norm": 0.6919362545013428,
      "learning_rate": 2e-05,
      "loss": 2.6294,
      "step": 2
    },
    {
      "epoch": 0.03428571428571429,
      "grad_norm": 0.5481895208358765,
      "learning_rate": 4e-05,
      "loss": 2.2964,
      "step": 3
    },
    {
      "epoch": 0.045714285714285714,
      "grad_norm": 0.5487572550773621,
      "learning_rate": 6e-05,
      "loss": 2.4396,
      "step": 4
    },
    {
      "epoch": 0.05714285714285714,
      "grad_norm": 0.4347265660762787,
      "learning_rate": 8e-05,
      "loss": 1.9945,
      "step": 5
    },
    {
      "epoch": 0.06857142857142857,
      "grad_norm": 0.30544084310531616,
      "learning_rate": 0.0001,
      "loss": 1.6271,
      "step": 6
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.5422291159629822,
      "learning_rate": 0.00012,
      "loss": 1.9165,
      "step": 7
    },
    {
      "epoch": 0.09142857142857143,
      "grad_norm": 0.6068659424781799,
      "learning_rate": 0.00014,
      "loss": 1.8726,
      "step": 8
    },
    {
      "epoch": 0.10285714285714286,
      "grad_norm": 0.7243181467056274,
      "learning_rate": 0.00016,
      "loss": 1.9115,
      "step": 9
    },
    {
      "epoch": 0.11428571428571428,
      "grad_norm": 1.0190335512161255,
      "learning_rate": 0.00018,
      "loss": 1.8431,
      "step": 10
    },
    {
      "epoch": 0.12571428571428572,
      "grad_norm": 0.8867117762565613,
      "learning_rate": 0.0002,
      "loss": 1.609,
      "step": 11
    },
    {
      "epoch": 0.13714285714285715,
      "grad_norm": 4.000432968139648,
      "learning_rate": 0.00019740259740259742,
      "loss": 1.6374,
      "step": 12
    },
    {
      "epoch": 0.14857142857142858,
      "grad_norm": 1.9752228260040283,
      "learning_rate": 0.0001948051948051948,
      "loss": 1.3293,
      "step": 13
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9535819888114929,
      "learning_rate": 0.00019220779220779222,
      "loss": 1.2099,
      "step": 14
    },
    {
      "epoch": 0.17142857142857143,
      "grad_norm": 0.5980181097984314,
      "learning_rate": 0.00018961038961038963,
      "loss": 1.0725,
      "step": 15
    },
    {
      "epoch": 0.18285714285714286,
      "grad_norm": 0.5852593779563904,
      "learning_rate": 0.000187012987012987,
      "loss": 0.981,
      "step": 16
    },
    {
      "epoch": 0.19428571428571428,
      "grad_norm": 0.5193873047828674,
      "learning_rate": 0.00018441558441558442,
      "loss": 0.8776,
      "step": 17
    },
    {
      "epoch": 0.2057142857142857,
      "grad_norm": 0.5756874084472656,
      "learning_rate": 0.00018181818181818183,
      "loss": 0.9856,
      "step": 18
    },
    {
      "epoch": 0.21714285714285714,
      "grad_norm": 0.38091567158699036,
      "learning_rate": 0.00017922077922077922,
      "loss": 0.7772,
      "step": 19
    },
    {
      "epoch": 0.22857142857142856,
      "grad_norm": 0.4239911139011383,
      "learning_rate": 0.00017662337662337663,
      "loss": 0.8887,
      "step": 20
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.4152296781539917,
      "learning_rate": 0.00017402597402597401,
      "loss": 0.8103,
      "step": 21
    },
    {
      "epoch": 0.25142857142857145,
      "grad_norm": 0.29792553186416626,
      "learning_rate": 0.00017142857142857143,
      "loss": 1.035,
      "step": 22
    },
    {
      "epoch": 0.26285714285714284,
      "grad_norm": 0.21360540390014648,
      "learning_rate": 0.00016883116883116884,
      "loss": 0.7912,
      "step": 23
    },
    {
      "epoch": 0.2742857142857143,
      "grad_norm": 0.2661169767379761,
      "learning_rate": 0.00016623376623376625,
      "loss": 0.7528,
      "step": 24
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 0.310954213142395,
      "learning_rate": 0.00016363636363636366,
      "loss": 0.8516,
      "step": 25
    },
    {
      "epoch": 0.29714285714285715,
      "grad_norm": 0.3144555985927582,
      "learning_rate": 0.00016103896103896104,
      "loss": 0.8995,
      "step": 26
    },
    {
      "epoch": 0.30857142857142855,
      "grad_norm": 0.33921951055526733,
      "learning_rate": 0.00015844155844155845,
      "loss": 0.7481,
      "step": 27
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3028716742992401,
      "learning_rate": 0.00015584415584415587,
      "loss": 0.9478,
      "step": 28
    },
    {
      "epoch": 0.3314285714285714,
      "grad_norm": 0.32042163610458374,
      "learning_rate": 0.00015324675324675325,
      "loss": 0.8657,
      "step": 29
    },
    {
      "epoch": 0.34285714285714286,
      "grad_norm": 0.2877737283706665,
      "learning_rate": 0.00015064935064935066,
      "loss": 0.7533,
      "step": 30
    },
    {
      "epoch": 0.35428571428571426,
      "grad_norm": 0.31762564182281494,
      "learning_rate": 0.00014805194805194807,
      "loss": 0.7911,
      "step": 31
    },
    {
      "epoch": 0.3657142857142857,
      "grad_norm": 0.29019153118133545,
      "learning_rate": 0.00014545454545454546,
      "loss": 0.5967,
      "step": 32
    },
    {
      "epoch": 0.37714285714285717,
      "grad_norm": 0.3682186007499695,
      "learning_rate": 0.00014285714285714287,
      "loss": 0.9343,
      "step": 33
    },
    {
      "epoch": 0.38857142857142857,
      "grad_norm": 0.26646140217781067,
      "learning_rate": 0.00014025974025974028,
      "loss": 0.7748,
      "step": 34
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.2938074767589569,
      "learning_rate": 0.00013766233766233766,
      "loss": 0.7745,
      "step": 35
    },
    {
      "epoch": 0.4114285714285714,
      "grad_norm": 0.2943902313709259,
      "learning_rate": 0.00013506493506493507,
      "loss": 0.8113,
      "step": 36
    },
    {
      "epoch": 0.4228571428571429,
      "grad_norm": 0.27837806940078735,
      "learning_rate": 0.00013246753246753249,
      "loss": 0.96,
      "step": 37
    },
    {
      "epoch": 0.4342857142857143,
      "grad_norm": 0.23148611187934875,
      "learning_rate": 0.00012987012987012987,
      "loss": 0.8464,
      "step": 38
    },
    {
      "epoch": 0.44571428571428573,
      "grad_norm": 0.26871636509895325,
      "learning_rate": 0.00012727272727272728,
      "loss": 0.8293,
      "step": 39
    },
    {
      "epoch": 0.45714285714285713,
      "grad_norm": 0.2644631862640381,
      "learning_rate": 0.00012467532467532467,
      "loss": 0.6746,
      "step": 40
    },
    {
      "epoch": 0.4685714285714286,
      "grad_norm": 0.17921191453933716,
      "learning_rate": 0.00012207792207792208,
      "loss": 0.8216,
      "step": 41
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.23434637486934662,
      "learning_rate": 0.00011948051948051949,
      "loss": 0.6782,
      "step": 42
    },
    {
      "epoch": 0.49142857142857144,
      "grad_norm": 0.23235923051834106,
      "learning_rate": 0.00011688311688311689,
      "loss": 1.0187,
      "step": 43
    },
    {
      "epoch": 0.5028571428571429,
      "grad_norm": 0.24732773005962372,
      "learning_rate": 0.00011428571428571428,
      "loss": 0.7637,
      "step": 44
    },
    {
      "epoch": 0.5142857142857142,
      "grad_norm": 0.2035788595676422,
      "learning_rate": 0.00011168831168831168,
      "loss": 0.9014,
      "step": 45
    },
    {
      "epoch": 0.5257142857142857,
      "grad_norm": 0.2956447899341583,
      "learning_rate": 0.00010909090909090909,
      "loss": 0.8882,
      "step": 46
    },
    {
      "epoch": 0.5371428571428571,
      "grad_norm": 0.22550898790359497,
      "learning_rate": 0.00010649350649350649,
      "loss": 0.8168,
      "step": 47
    },
    {
      "epoch": 0.5485714285714286,
      "grad_norm": 0.21643409132957458,
      "learning_rate": 0.00010389610389610389,
      "loss": 0.8942,
      "step": 48
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.236613467335701,
      "learning_rate": 0.0001012987012987013,
      "loss": 0.7805,
      "step": 49
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.24525362253189087,
      "learning_rate": 9.870129870129871e-05,
      "loss": 0.772,
      "step": 50
    },
    {
      "epoch": 0.5828571428571429,
      "grad_norm": 0.22208981215953827,
      "learning_rate": 9.610389610389611e-05,
      "loss": 0.6202,
      "step": 51
    },
    {
      "epoch": 0.5942857142857143,
      "grad_norm": 0.24772506952285767,
      "learning_rate": 9.35064935064935e-05,
      "loss": 0.7576,
      "step": 52
    },
    {
      "epoch": 0.6057142857142858,
      "grad_norm": 0.24817724525928497,
      "learning_rate": 9.090909090909092e-05,
      "loss": 0.6389,
      "step": 53
    },
    {
      "epoch": 0.6171428571428571,
      "grad_norm": 0.225065216422081,
      "learning_rate": 8.831168831168831e-05,
      "loss": 0.7448,
      "step": 54
    },
    {
      "epoch": 0.6285714285714286,
      "grad_norm": 0.25167956948280334,
      "learning_rate": 8.571428571428571e-05,
      "loss": 0.6173,
      "step": 55
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.2854595482349396,
      "learning_rate": 8.311688311688312e-05,
      "loss": 0.8124,
      "step": 56
    },
    {
      "epoch": 0.6514285714285715,
      "grad_norm": 0.1974852830171585,
      "learning_rate": 8.051948051948052e-05,
      "loss": 0.8912,
      "step": 57
    },
    {
      "epoch": 0.6628571428571428,
      "grad_norm": 0.2661234438419342,
      "learning_rate": 7.792207792207793e-05,
      "loss": 0.6268,
      "step": 58
    },
    {
      "epoch": 0.6742857142857143,
      "grad_norm": 0.2294500321149826,
      "learning_rate": 7.532467532467533e-05,
      "loss": 0.7135,
      "step": 59
    },
    {
      "epoch": 0.6857142857142857,
      "grad_norm": 0.2768077850341797,
      "learning_rate": 7.272727272727273e-05,
      "loss": 0.7558,
      "step": 60
    },
    {
      "epoch": 0.6971428571428572,
      "grad_norm": 0.28068313002586365,
      "learning_rate": 7.012987012987014e-05,
      "loss": 0.7015,
      "step": 61
    },
    {
      "epoch": 0.7085714285714285,
      "grad_norm": 0.28258007764816284,
      "learning_rate": 6.753246753246754e-05,
      "loss": 1.221,
      "step": 62
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.26767587661743164,
      "learning_rate": 6.493506493506494e-05,
      "loss": 0.8611,
      "step": 63
    },
    {
      "epoch": 0.7314285714285714,
      "grad_norm": 0.25981104373931885,
      "learning_rate": 6.233766233766233e-05,
      "loss": 0.7679,
      "step": 64
    },
    {
      "epoch": 0.7428571428571429,
      "grad_norm": 0.2372778058052063,
      "learning_rate": 5.9740259740259744e-05,
      "loss": 0.7488,
      "step": 65
    },
    {
      "epoch": 0.7542857142857143,
      "grad_norm": 0.24636389315128326,
      "learning_rate": 5.714285714285714e-05,
      "loss": 0.8661,
      "step": 66
    },
    {
      "epoch": 0.7657142857142857,
      "grad_norm": 0.34709444642066956,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 0.7481,
      "step": 67
    },
    {
      "epoch": 0.7771428571428571,
      "grad_norm": 0.23843415081501007,
      "learning_rate": 5.1948051948051944e-05,
      "loss": 0.8516,
      "step": 68
    },
    {
      "epoch": 0.7885714285714286,
      "grad_norm": 0.24171918630599976,
      "learning_rate": 4.9350649350649355e-05,
      "loss": 0.8127,
      "step": 69
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.23740966618061066,
      "learning_rate": 4.675324675324675e-05,
      "loss": 0.7631,
      "step": 70
    },
    {
      "epoch": 0.8114285714285714,
      "grad_norm": 0.2278294563293457,
      "learning_rate": 4.415584415584416e-05,
      "loss": 0.7492,
      "step": 71
    },
    {
      "epoch": 0.8228571428571428,
      "grad_norm": 0.25051620602607727,
      "learning_rate": 4.155844155844156e-05,
      "loss": 0.7532,
      "step": 72
    },
    {
      "epoch": 0.8342857142857143,
      "grad_norm": 0.3053903877735138,
      "learning_rate": 3.8961038961038966e-05,
      "loss": 0.6785,
      "step": 73
    },
    {
      "epoch": 0.8457142857142858,
      "grad_norm": 0.32093310356140137,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 0.836,
      "step": 74
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 0.2546333372592926,
      "learning_rate": 3.376623376623377e-05,
      "loss": 0.8299,
      "step": 75
    },
    {
      "epoch": 0.8685714285714285,
      "grad_norm": 0.27306079864501953,
      "learning_rate": 3.1168831168831166e-05,
      "loss": 0.8442,
      "step": 76
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.2084064930677414,
      "learning_rate": 2.857142857142857e-05,
      "loss": 0.8828,
      "step": 77
    },
    {
      "epoch": 0.8914285714285715,
      "grad_norm": 0.22426535189151764,
      "learning_rate": 2.5974025974025972e-05,
      "loss": 0.9039,
      "step": 78
    },
    {
      "epoch": 0.9028571428571428,
      "grad_norm": 0.2643186151981354,
      "learning_rate": 2.3376623376623376e-05,
      "loss": 0.686,
      "step": 79
    },
    {
      "epoch": 0.9142857142857143,
      "grad_norm": 0.21921086311340332,
      "learning_rate": 2.077922077922078e-05,
      "loss": 0.6723,
      "step": 80
    },
    {
      "epoch": 0.9257142857142857,
      "grad_norm": 0.24328987300395966,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.7488,
      "step": 81
    },
    {
      "epoch": 0.9371428571428572,
      "grad_norm": 0.2537625730037689,
      "learning_rate": 1.5584415584415583e-05,
      "loss": 0.8799,
      "step": 82
    },
    {
      "epoch": 0.9485714285714286,
      "grad_norm": 0.26144224405288696,
      "learning_rate": 1.2987012987012986e-05,
      "loss": 0.6583,
      "step": 83
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.2603833079338074,
      "learning_rate": 1.038961038961039e-05,
      "loss": 0.7732,
      "step": 84
    },
    {
      "epoch": 0.9714285714285714,
      "grad_norm": 0.24854902923107147,
      "learning_rate": 7.792207792207792e-06,
      "loss": 0.8313,
      "step": 85
    },
    {
      "epoch": 0.9828571428571429,
      "grad_norm": 0.3084344267845154,
      "learning_rate": 5.194805194805195e-06,
      "loss": 0.8921,
      "step": 86
    },
    {
      "epoch": 0.9942857142857143,
      "grad_norm": 0.24509383738040924,
      "learning_rate": 2.5974025974025976e-06,
      "loss": 0.7345,
      "step": 87
    }
  ],
  "logging_steps": 1,
  "max_steps": 87,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1677707145965568.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
