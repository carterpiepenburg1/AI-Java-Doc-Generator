{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7001dec90f00a3d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T08:51:49.395873600Z",
     "start_time": "2025-05-05T08:51:48.947306400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63712c8cd244810873fa2395a6abcf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78e2e54a04c3f84f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T08:35:39.556990300Z",
     "start_time": "2025-05-05T08:35:39.461763500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f9433c-bc38-42e9-a1ec-7ad3c29d6a06",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c380aab-ee59-49e7-a5d0-3c6d281984bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T08:35:45.003174900Z",
     "start_time": "2025-05-05T08:35:42.804288500Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "dataset = load_dataset(\"Nan-Do/code-search-net-java\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3587821-8c14-4e3b-a01f-62f9db315463",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T07:22:29.242556300Z",
     "start_time": "2025-05-05T07:22:29.234671100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available splits: ['train']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available splits:\", list(dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d4cc4a-4894-414c-9a14-fb5d710495b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T08:35:48.431945200Z",
     "start_time": "2025-05-05T08:35:48.413615400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url', 'partition', 'summary']\n"
     ]
    }
   ],
   "source": [
    "# Access the train split\n",
    "train_dataset = dataset['train']\n",
    "\n",
    "# Print column names\n",
    "column_names = train_dataset.column_names\n",
    "print(\"Column names:\", column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "727860d4-b138-4960-822f-ffd4a8795ea1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T07:22:29.261016900Z",
     "start_time": "2025-05-05T07:22:29.254321300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in train dataset: ['repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url', 'partition', 'summary']\n",
      "Number of examples in train dataset: 495953\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in train dataset:\", train_dataset.column_names)\n",
    "print(f\"Number of examples in train dataset: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a2d5f52-1818-48e8-8856-07081b8599b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T08:35:53.296282900Z",
     "start_time": "2025-05-05T08:35:53.290087500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a filtered dataset with only the first 1000 examples\n",
    "subset_size = 1000\n",
    "dataset = train_dataset.select(range(subset_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95bd5f0-251e-4563-8660-203e61f8e049",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T08:35:54.568483300Z",
     "start_time": "2025-05-05T08:35:54.558113100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in filtered dataset: ['repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url', 'partition', 'summary']\n",
      "Number of examples in filtered dataset: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in filtered dataset:\", dataset.column_names)\n",
    "print(f\"Number of examples in filtered dataset: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72dba0-a20d-44d2-87c6-36b2c6ef4b02",
   "metadata": {},
   "source": [
    "# Converting dataset to ShareGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9034215-530c-4c41-887a-3d81d72a8ba3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T08:35:56.399107400Z",
     "start_time": "2025-05-05T08:35:56.391180100Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_sharegpt(dataset, merged_prompt, output_column_name, conversation_extension=1):\n",
    "    \"\"\"\n",
    "    Convert dataset to ShareGPT format with proper variable substitution\n",
    "\n",
    "    Args:\n",
    "        dataset: The source dataset\n",
    "        merged_prompt: Template string with {column_name} placeholders\n",
    "        output_column_name: Column to use as the output/completion\n",
    "        conversation_extension: Number of examples to combine into a single conversation\n",
    "    \"\"\"\n",
    "    formatted_data = []\n",
    "\n",
    "    for i in range(0, len(dataset), conversation_extension):\n",
    "        conversation = []\n",
    "\n",
    "        # Process each example in the current conversation window\n",
    "        for j in range(i, min(i + conversation_extension, len(dataset))):\n",
    "            example = dataset[j]\n",
    "\n",
    "            # Format the prompt by substituting variables\n",
    "            prompt = merged_prompt\n",
    "            for column in dataset.column_names:\n",
    "                if column in merged_prompt and column in example:\n",
    "                    placeholder = \"{\" + column + \"}\"\n",
    "                    prompt = prompt.replace(placeholder, str(example[column]))\n",
    "\n",
    "            # Add the human message\n",
    "            conversation.append({\n",
    "                \"from\": \"human\",\n",
    "                \"value\": prompt\n",
    "            })\n",
    "\n",
    "            # Add the assistant message\n",
    "            conversation.append({\n",
    "                \"from\": \"assistant\",\n",
    "                \"value\": example[output_column_name]\n",
    "            })\n",
    "\n",
    "        # Add the conversation to the formatted data\n",
    "        formatted_data.append({\"conversations\": conversation})\n",
    "\n",
    "    return formatted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af2722b-1564-422d-b7ad-62299d5549cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T08:35:57.717197300Z",
     "start_time": "2025-05-05T08:35:57.486980Z"
    }
   },
   "outputs": [],
   "source": [
    "# For code explanation\n",
    "code_explain_dataset = to_sharegpt(\n",
    "    dataset,\n",
    "    merged_prompt = \"Explain what this Java code does: {code}\",\n",
    "    output_column_name = \"docstring\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bae3b21a-a8c5-4eae-854d-ecf98a27f3fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T08:35:58.305867600Z",
     "start_time": "2025-05-05T08:35:58.295748300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': [{'from': 'human',\n",
       "   'value': 'Explain what this Java code does: protected final void bindIndexed(ConfigurationPropertyName name, Bindable<?> target,\\n\\t\\t\\tAggregateElementBinder elementBinder, ResolvableType aggregateType,\\n\\t\\t\\tResolvableType elementType, IndexedCollectionSupplier result) {\\n\\t\\tfor (ConfigurationPropertySource source : getContext().getSources()) {\\n\\t\\t\\tbindIndexed(source, name, target, elementBinder, result, aggregateType,\\n\\t\\t\\t\\t\\telementType);\\n\\t\\t\\tif (result.wasSupplied() && result.get() != null) {\\n\\t\\t\\t\\treturn;\\n\\t\\t\\t}\\n\\t\\t}\\n\\t}'},\n",
       "  {'from': 'assistant',\n",
       "   'value': 'Bind indexed elements to the supplied collection.\\n@param name the name of the property to bind\\n@param target the target bindable\\n@param elementBinder the binder to use for elements\\n@param aggregateType the aggregate type, may be a collection or an array\\n@param elementType the element type\\n@param result the destination for results'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_explain_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54206b18-de29-49ef-bec5-6c8b97a8aa02",
   "metadata": {},
   "source": [
    "# Initialize Model and Token Register"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carte\\compsci\\411\\aiproject\\new.venv\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:330: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:28.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"cuda:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.4.7: Fast Qwen2 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 3060 Laptop GPU. Num GPUs = 1. Max memory: 6.0 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu128. CUDA: 8.6. CUDA Toolkit: 12.8. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Qwen2.5-1.5B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T08:36:09.955907800Z",
     "start_time": "2025-05-05T08:36:09.902647300Z"
    }
   },
   "id": "63293d97-60b0-4843-96bf-cec7a49c5f01",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "643bc74f-ece1-445c-bb16-38c1dada7dd9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-05T07:22:29.547826400Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# First, convert your list to a Hugging Face Dataset\n",
    "code_explain_dataset_hf = Dataset.from_list(code_explain_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f224b024-6e17-44cd-897e-d8aa62c84335",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-05-05T07:22:29.548830500Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ad66a04db0433c9fbddd96a000294a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Standardizing formats (num_proc=16):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import standardize_sharegpt\n",
    "dataset = standardize_sharegpt(code_explain_dataset_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "118b7cd7-5e9e-42f4-b171-82b436d29a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: We automatically added an EOS token to stop endless generations.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88171b86a98d46bf826e9b5011d41be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import apply_chat_template\n",
    "chat_template = \"\"\"\n",
    "{SYSTEM}\n",
    "USER: {INPUT}\n",
    "ASSISTANT: {OUTPUT}\"\"\"\n",
    "\n",
    "default_system_message = \"\"\"You are generating brief documentation for a Java code snippet. \"\n",
    "    \"Your response MUST be a single paragraph with NO bullet points, NO line breaks, and NO section headers. \"\n",
    "    \"Do NOT explain the prompt. Just output the summary. \"\n",
    "    \"Keep your explanation short and focused. Avoid repetition. \"\n",
    "    \"Summarize ONLY the core logic and purpose of the code.\\n\\nSummary (one paragraph only):\"\"\"\n",
    "\n",
    "# Use this system message with the apply_chat_template function\n",
    "dataset = apply_chat_template(\n",
    "    dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    chat_template = chat_template,\n",
    "    default_system_message = default_system_message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4932e6b0-786d-45fd-9a98-d40f848c3f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversations': [{'content': 'Explain what this Java code does: public void addServletRegistrationBeans(\\n\\t\\t\\tServletRegistrationBean<?>... servletRegistrationBeans) {\\n\\t\\tAssert.notNull(servletRegistrationBeans,\\n\\t\\t\\t\\t\"ServletRegistrationBeans must not be null\");\\n\\t\\tCollections.addAll(this.servletRegistrationBeans, servletRegistrationBeans);\\n\\t}',\n",
       "   'role': 'user'},\n",
       "  {'content': 'Add {@link ServletRegistrationBean}s for the filter.\\n@param servletRegistrationBeans the servlet registration beans to add\\n@see #setServletRegistrationBeans',\n",
       "   'role': 'assistant'}],\n",
       " 'text': 'You are generating brief documentation for a Java code snippet. \"\\n    \"Your response MUST be a single paragraph with NO bullet points, NO line breaks, and NO section headers. \"\\n    \"Do NOT explain the prompt. Just output the summary. \"\\n    \"Keep your explanation short and focused. Avoid repetition. \"\\n    \"Summarize ONLY the core logic and purpose of the code.\\n\\nSummary (one paragraph only):\\nUSER: Explain what this Java code does: public void addServletRegistrationBeans(\\n\\t\\t\\tServletRegistrationBean<?>... servletRegistrationBeans) {\\n\\t\\tAssert.notNull(servletRegistrationBeans,\\n\\t\\t\\t\\t\"ServletRegistrationBeans must not be null\");\\n\\t\\tCollections.addAll(this.servletRegistrationBeans, servletRegistrationBeans);\\n\\t}\\nASSISTANT: Add {@link ServletRegistrationBean}s for the filter.\\n@param servletRegistrationBeans the servlet registration beans to add\\n@see #setServletRegistrationBeans<|endoftext|>'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ed04283-6801-4319-b610-98861af22763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "441f2f262afa49bf91de7cbae8bb70b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01375ad851e542b3b820f1f0ddfad7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aec0540ebc1f41e988e7f79516c85fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/384 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/CarterPiepenburg/code-search-net-java-docgen/commit/d5274eb5af949f2f8bd5377f4279c9abf7a83c11', commit_message='Upload dataset', commit_description='', oid='d5274eb5af949f2f8bd5377f4279c9abf7a83c11', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/CarterPiepenburg/code-search-net-java-docgen', endpoint='https://huggingface.co', repo_type='dataset', repo_id='CarterPiepenburg/code-search-net-java-docgen'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.push_to_hub(\"CarterPiepenburg/code-search-net-java-docgen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ebf36-c7cf-435d-9daf-a2874ed6c5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
